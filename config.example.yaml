# Voice-to-Speech Local — Configuration Template
# Copy this file to config.yaml and adjust settings as needed.

# Default transcription language.
# Supported: fr, en, es, pt, hi, de, nl, it, ar, ru, zh, ja, ko
language: "fr"

# Maximum file upload size in MB (50-1024)
max_upload_size_mb: 500

# Global keyboard shortcuts (Tauri)
shortcuts:
  toggle_dictation: "Ctrl+Shift+D"      # Activate/deactivate dictation mode
  toggle_transcription: "Ctrl+Shift+T"  # Open/focus transcription window

# Model settings (OpenAI Whisper via faster-whisper)
models:
  transcription:
    model_size: "auto"          # auto, tiny, base, small, medium, large-v3, large-v3-turbo
                                # auto = large-v3-turbo on GPU, small on CPU
    device: "auto"              # auto, cuda, cpu
    compute_type: "auto"        # auto, float16, int8, int8_float16
    beam_size: 5                # 1 = greedy (fast), 5 = beam search (accurate)
    vad_filter: true            # Skip silent regions (recommended)
    vad_min_silence_ms: 500     # Min silence duration (ms) for VAD to split (100-3000)
    temperature: 0.0            # 0 = deterministic greedy (faster), >0 = sampling
    buffer_duration_s: 10.0     # Seconds to buffer before transcribing (1-30)
    initial_prompt: null        # Prompt to prime the model, e.g. "Bonjour, transcription en français."
    overlap_duration_s: 1.0     # Audio overlap between chunks to avoid cut words (0-5)
    end_padding_ms: 300         # Silence appended before transcription to avoid truncation (0-1000)
    post_roll_ms: 1200          # Extra audio capture after stop to avoid cutting last words (0-5000)
    repetition_penalty: 1.15    # Penalizes repeated tokens to prevent hallucination loops (1.0-2.0)
    no_repeat_ngram_size: 4     # Prevents repeating any N-gram of this size (0 = disabled, 3-6)
    compression_ratio_threshold: 2.4  # Discard segments above this ratio (hallucination indicator)
    log_prob_threshold: -1.0    # Discard segments with avg log prob below this (-5.0 to 0.0)
    hallucination_max_repeats: 3  # Max phrase repeats before chunk is discarded (2-10)

  # LLM post-processing (summarization, text rewriting)
  # Uses any OpenAI-compatible API (Ollama, LM Studio, vLLM, cloud providers)
  llm:
    enabled: false                          # Set to true to enable LLM features
    api_url: "http://localhost:11434/v1"    # Ollama default endpoint
    api_key: "ollama"                       # API key ('ollama' for local, real key for cloud)
    model: "mistral:7b"                     # Model name (must be pulled in Ollama first)
    temperature: 0.3                        # Lower = more deterministic
    max_tokens: 512                         # Max output tokens for summary/rewrite
    auto_summarize: true                    # Auto-generate summary after each session

# Semantic search settings
search:
  # Embedding model for semantic search (multilingual recommended for non-English)
  # paraphrase-multilingual-MiniLM-L12-v2 — 50+ languages, 384-dim (default)
  # all-MiniLM-L6-v2 — English-optimized, 384-dim (ChromaDB's original default)
  embedding_model: "paraphrase-multilingual-MiniLM-L12-v2"

# Audio capture settings
audio:
  sample_rate: 16000          # Sample rate in Hz (16kHz for Whisper)
  channels: 1                 # Mono audio
  device: "default"           # Audio input device name or index
  chunk_duration_ms: 80       # Duration per audio chunk in ms

# Overlay window settings
overlay:
  enabled: true
  position: "top-right"       # top-left, top-right, bottom-left, bottom-right
  opacity: 0.85               # 0.1 to 1.0
  size: "small"               # small, medium
  show_language: true          # Show language code (FR, EN...)
  show_mode: false             # Show active mode (TRS/DIC)
  show_duration: false         # Show recording duration timer

# Storage settings
storage:
  db_path: "./data/sessions.db"  # Path to SQLite database

# Backend server settings
backend:
  host: "127.0.0.1"
  port: 8001
